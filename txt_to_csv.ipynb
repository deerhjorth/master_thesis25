{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/yntdr4q97s74g63m6p8162rw0000gn/T/ipykernel_79249/581249992.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "current limit exceeds maximum limit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mresource\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Increase memory limit to 16GB (adjust as needed)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mresource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetrlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRLIMIT_AS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: current limit exceeds maximum limit"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import resource\n",
    "# Increase memory limit to 16GB (adjust as needed)\n",
    "resource.setrlimit(resource.RLIMIT_AS, (1 * 1024 * 1024 * 1024, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .txt file and clean up the surrounding pipes\n",
    "file_path = 'lob_issue.txt'\n",
    "output_path = '/Users/christianhjorth/Downloads/Lobby_csv/lob_issue.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File converted and saved as /Users/christianhjorth/Downloads/Lobby_csv/lob_bills.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the .txt file and clean up the surrounding pipes\n",
    "file_path = 'lob_issue.txt'\n",
    "output_path = '/Users/christianhjorth/Downloads/Lobby_csv/lob_issue.csv'\n",
    "\n",
    "# Read and preprocess the .txt file\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "    lines = []\n",
    "    for line in file:\n",
    "        # Handle fields enclosed in |...| and empty fields\n",
    "        fields = re.split(r',(?=(?:[^\\|]*\\|[^\\|]*\\|)*[^\\|]*$)', line.strip())\n",
    "        # Clean each field: remove enclosing pipes and replace empty fields with NULL\n",
    "        fields = [field.strip('|').strip() if field.strip('|').strip() else 'NULL' for field in fields]\n",
    "        lines.append(fields)\n",
    "\n",
    "df = pd.DataFrame(lines)\n",
    "\n",
    "# Save the DataFrame as a .csv file\n",
    "df.to_csv(output_path, index=False, header=False)  # Set header=True if adding column names\n",
    "\n",
    "print(f\"File converted and saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File converted and saved as /Users/christianhjorth/Downloads/Lobby_csv/lob_issue.csv\n"
     ]
    }
   ],
   "source": [
    "# this works\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the .txt file and clean up the surrounding pipes\n",
    "file_path = 'lob_lobbyist.txt'\n",
    "output_path = '/Users/christianhjorth/Downloads/Lobby_csv/lob_lobbyist.csv'\n",
    "\n",
    "# Read and preprocess the .txt file\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "    lines = []\n",
    "    current_entry = \"\"\n",
    "\n",
    "    for line in file:\n",
    "        # Replace newlines with a tab and accumulate lines\n",
    "        current_entry += line.strip() + '\\t'\n",
    "\n",
    "        # Check if the current entry is complete (i.e., has balanced pipes)\n",
    "        if current_entry.count('|') % 2 == 0:\n",
    "            # Remove the trailing tab added after the last line\n",
    "            current_entry = current_entry.rstrip('\\t')\n",
    "            # Process the complete entry\n",
    "            fields = re.split(r',(?=(?:[^\\|]*\\|[^\\|]*\\|)*[^\\|]*$)', current_entry)\n",
    "            fields = [field.strip('|').strip() if field.strip('|').strip() else 'NULL' for field in fields]\n",
    "            lines.append(fields)\n",
    "            current_entry = \"\"  # Reset for the next entry\n",
    "\n",
    "df = pd.DataFrame(lines)\n",
    "\n",
    "# Save the DataFrame as a .csv file\n",
    "df.to_csv(output_path, index=False, header=False)  # Set header=True if adding column names\n",
    "\n",
    "print(f\"File converted and saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 6092739, Half point: 3046369\n",
      "File converted and saved as /Users/christianhjorth/Downloads/Lobby_csv/lob_issue1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the .txt file and clean up the surrounding pipes\n",
    "file_path = 'lob_issue.txt'\n",
    "output_path = '/Users/christianhjorth/Downloads/Lobby_csv/lob_issue1.csv'\n",
    "process_first_half = True  # Toggle this to False to process second half\n",
    "\n",
    "# First count total lines\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "    total_lines = sum(1 for _ in file)\n",
    "    half_point = total_lines // 2\n",
    "    print(f\"Total lines: {total_lines}, Half point: {half_point}\")\n",
    "\n",
    "# Read and preprocess the .txt file\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "    lines = []\n",
    "    for i, line in enumerate(file):\n",
    "        # Skip lines based on which half we're processing\n",
    "        if process_first_half and i >= half_point:\n",
    "            break\n",
    "        if not process_first_half and i < half_point:\n",
    "            continue\n",
    "            \n",
    "        # Handle fields enclosed in |...| and empty fields\n",
    "        fields = re.split(r',(?=(?:[^\\|]*\\|[^\\|]*\\|)*[^\\|]*$)', line.strip())\n",
    "        # Clean each field: remove enclosing pipes and replace empty fields with NULL\n",
    "        fields = [field.strip('|').strip() if field.strip('|').strip() else 'NULL' for field in fields]\n",
    "        lines.append(fields)\n",
    "\n",
    "df = pd.DataFrame(lines)\n",
    "\n",
    "# Save the DataFrame as a .csv file\n",
    "df.to_csv(output_path, index=False, header=False)  # Set header=True if adding column names\n",
    "\n",
    "print(f\"File converted and saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    processed_lines = []\n",
    "    for line in chunk:\n",
    "        # Handle fields enclosed in |...| and empty fields\n",
    "        fields = re.split(r',(?=(?:[^\\|]*\\|[^\\|]*\\|)*[^\\|]*$)', line.strip())\n",
    "        # Clean each field: remove enclosing pipes and replace empty fields with NULL\n",
    "        fields = [field.strip('|').strip() if field.strip('|').strip() else 'NULL' for field in fields]\n",
    "        processed_lines.append(fields)\n",
    "    return processed_lines\n",
    "\n",
    "# Read and preprocess the .txt file in chunks\n",
    "chunksize = 6100000  # Adjust this number based on your available memory\n",
    "first_chunk = True\n",
    "\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "    while True:\n",
    "        # Read a chunk of lines\n",
    "        chunk = list(islice(file, chunksize))\n",
    "        if not chunk:\n",
    "            break\n",
    "            \n",
    "        # Process the chunk\n",
    "        processed_lines = process_chunk(chunk)\n",
    "        \n",
    "        # Convert to DataFrame and save\n",
    "        df = pd.DataFrame(processed_lines)\n",
    "        \n",
    "        # Write to CSV (append mode after first chunk)\n",
    "        df.to_csv(output_path, \n",
    "                 mode='w' if first_chunk else 'a',\n",
    "                 header=False, \n",
    "                 index=False)\n",
    "        \n",
    "        first_chunk = False\n",
    "        print(f\"Processed {chunksize} lines...\")\n",
    "\n",
    "print(f\"File converted and saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.DataFrame(lines)\n",
    "\n",
    "# # Save the DataFrame as a .csv file\n",
    "# df.to_csv(output_path, index=False, header=False)  # Set header=True if adding column names\n",
    "\n",
    "# print(f\"File converted and saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82c5f661-a637-45ad-a3a6-b5ba18cf8962</td>\n",
       "      <td>ASTRAZENECA PHARMACEUTICALS LP</td>\n",
       "      <td>AstraZeneca Pharmaceuticals</td>\n",
       "      <td>NULL</td>\n",
       "      <td>ASTRAZENECA PHARMACEUTICALS LP</td>\n",
       "      <td>AstraZeneca Pharmaceuticals</td>\n",
       "      <td>AstraZeneca PLC</td>\n",
       "      <td>1370000.0</td>\n",
       "      <td>H4300</td>\n",
       "      <td>pac</td>\n",
       "      <td>x</td>\n",
       "      <td>NULL</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2021</td>\n",
       "      <td>q4a</td>\n",
       "      <td>FOURTH QUARTER AMENDMENT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84ad3a9e-5864-4227-a802-e268fbf37237</td>\n",
       "      <td>DAVID L. HORNE, LLC</td>\n",
       "      <td>David L Horne LLC</td>\n",
       "      <td>y</td>\n",
       "      <td>MULTIFAMILY LENDERS COUNCIL</td>\n",
       "      <td>Multifamily Lenders Council</td>\n",
       "      <td>Multifamily Lenders Council</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>F4600</td>\n",
       "      <td>wda16</td>\n",
       "      <td>n</td>\n",
       "      <td>NULL</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2021</td>\n",
       "      <td>q4</td>\n",
       "      <td>FOURTH QUARTER REPORT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85b111b1-5d2e-4107-bc24-0921316e29a5</td>\n",
       "      <td>ECHELON GOVERNMENT AFFAIRS</td>\n",
       "      <td>Echelon Government Affairs</td>\n",
       "      <td>y</td>\n",
       "      <td>THE ALBERS GROUP</td>\n",
       "      <td>Albers Group</td>\n",
       "      <td>Albers Group</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>Y4000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>n</td>\n",
       "      <td>NULL</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2021</td>\n",
       "      <td>q4</td>\n",
       "      <td>FOURTH QUARTER REPORT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87822a14-12de-478c-a34d-010fa503e539</td>\n",
       "      <td>WTA -- ADVOCATES FOR RURAL BROADBAND</td>\n",
       "      <td>Western Telecommunications Alliance</td>\n",
       "      <td>NULL</td>\n",
       "      <td>WTA -- ADVOCATES FOR RURAL BROADBAND</td>\n",
       "      <td>Western Telecommunications Alliance</td>\n",
       "      <td>Western Telecommunications Alliance</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>C4000</td>\n",
       "      <td>pac</td>\n",
       "      <td>p</td>\n",
       "      <td>NULL</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2021</td>\n",
       "      <td>q4</td>\n",
       "      <td>FOURTH QUARTER REPORT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87ff989d-9d12-4fef-84ef-ab69cd616894</td>\n",
       "      <td>FINANCIAL EXECUTIVES INTERNATIONAL</td>\n",
       "      <td>Financial Executives International</td>\n",
       "      <td>NULL</td>\n",
       "      <td>FINANCIAL EXECUTIVES INTERNATIONAL</td>\n",
       "      <td>Financial Executives International</td>\n",
       "      <td>Financial Executives International</td>\n",
       "      <td>21650.0</td>\n",
       "      <td>F5000</td>\n",
       "      <td>Hvr06</td>\n",
       "      <td>p</td>\n",
       "      <td>NULL</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>2021</td>\n",
       "      <td>q4</td>\n",
       "      <td>FOURTH QUARTER REPORT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0                                     1   \\\n",
       "0  82c5f661-a637-45ad-a3a6-b5ba18cf8962        ASTRAZENECA PHARMACEUTICALS LP   \n",
       "1  84ad3a9e-5864-4227-a802-e268fbf37237                   DAVID L. HORNE, LLC   \n",
       "2  85b111b1-5d2e-4107-bc24-0921316e29a5            ECHELON GOVERNMENT AFFAIRS   \n",
       "3  87822a14-12de-478c-a34d-010fa503e539  WTA -- ADVOCATES FOR RURAL BROADBAND   \n",
       "4  87ff989d-9d12-4fef-84ef-ab69cd616894    FINANCIAL EXECUTIVES INTERNATIONAL   \n",
       "\n",
       "                                    2     3   \\\n",
       "0          AstraZeneca Pharmaceuticals  NULL   \n",
       "1                    David L Horne LLC     y   \n",
       "2           Echelon Government Affairs     y   \n",
       "3  Western Telecommunications Alliance  NULL   \n",
       "4   Financial Executives International  NULL   \n",
       "\n",
       "                                     4                                    5   \\\n",
       "0        ASTRAZENECA PHARMACEUTICALS LP          AstraZeneca Pharmaceuticals   \n",
       "1           MULTIFAMILY LENDERS COUNCIL          Multifamily Lenders Council   \n",
       "2                      THE ALBERS GROUP                         Albers Group   \n",
       "3  WTA -- ADVOCATES FOR RURAL BROADBAND  Western Telecommunications Alliance   \n",
       "4    FINANCIAL EXECUTIVES INTERNATIONAL   Financial Executives International   \n",
       "\n",
       "                                    6          7      8      9  10    11 12  \\\n",
       "0                      AstraZeneca PLC  1370000.0  H4300    pac  x  NULL  y   \n",
       "1          Multifamily Lenders Council    15000.0  F4600  wda16  n  NULL  y   \n",
       "2                         Albers Group    10000.0  Y4000   NULL  n  NULL  y   \n",
       "3  Western Telecommunications Alliance    75000.0  C4000    pac  p  NULL  y   \n",
       "4   Financial Executives International    21650.0  F5000  Hvr06  p  NULL  y   \n",
       "\n",
       "  13    14   15                        16    17  \n",
       "0  y  2021  q4a  FOURTH QUARTER AMENDMENT  NULL  \n",
       "1  y  2021   q4     FOURTH QUARTER REPORT  NULL  \n",
       "2  y  2021   q4     FOURTH QUARTER REPORT  NULL  \n",
       "3  y  2021   q4     FOURTH QUARTER REPORT  NULL  \n",
       "4  y  2021   q4     FOURTH QUARTER REPORT  NULL  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lines)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File converted and saved as lob_lobbying.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame as a .csv file\n",
    "df.to_csv(output_path, index=False, header=False)  # Set header=True if adding column names\n",
    "\n",
    "print(f\"File converted and saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1544073, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "# Read the .txt file and clean up the surrounding pipes\n",
    "file_path = 'lob_lobbying.txt'\n",
    "output_path = 'lob_lobbying.csv'\n",
    "\n",
    "# Read and preprocess the .txt file\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "    lines = []\n",
    "    for line in file:\n",
    "        # Handle fields enclosed in |...| and empty fields\n",
    "        fields = re.split(r',(?=(?:[^\\|]*\\|[^\\|]*\\|)*[^\\|]*$)', line.strip())\n",
    "        # Clean each field: remove enclosing pipes and replace empty fields with NULL\n",
    "        fields = [field.strip('|').strip() if field.strip('|').strip() else 'NULL' for field in fields]\n",
    "        lines.append(fields)\n",
    "\n",
    "df = pd.DataFrame(lines)\n",
    "\n",
    "# Save the DataFrame as a .csv file\n",
    "df.to_csv(output_path, index=False, header=False)  # Set header=True if adding column names\n",
    "\n",
    "print(f\"File converted and saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Specify the folder containing the .txt files\n",
    "input_folder = '/Users/christianhjorth/Downloads/Lobby'\n",
    "output_folder = '/Users/christianhjorth/Downloads/Lobby_csv'\n",
    "\n",
    "# Process each .txt file in the folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.txt'):  # Process only .txt files\n",
    "        input_path = os.path.join(input_folder, file_name)\n",
    "        output_path = os.path.join(output_folder, file_name.replace('.txt', '.csv'))\n",
    "        \n",
    "        # Read and preprocess the .txt file\n",
    "        with open(input_path, 'r', encoding='ISO-8859-1') as file:\n",
    "            lines = []\n",
    "            for line in file:\n",
    "                # Handle fields enclosed in |...| and empty fields\n",
    "                fields = re.split(r',(?=(?:[^\\|]*\\|[^\\|]*\\|)*[^\\|]*$)', line.strip())\n",
    "                # Clean each field: remove enclosing pipes and replace empty fields with NULL\n",
    "                fields = [field.strip('|').strip() if field.strip('|').strip() else 'NULL' for field in fields]\n",
    "                lines.append(fields)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(lines)\n",
    "        \n",
    "        # Save as .csv\n",
    "        df.to_csv(output_path, index=False, header=False)  # Set header=True if adding column names\n",
    "        print(f\"Converted {file_name} to {output_path}\")\n",
    "\n",
    "print(\"All files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
